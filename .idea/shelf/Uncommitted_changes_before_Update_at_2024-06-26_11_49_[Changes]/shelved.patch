Index: src/beamformer.cpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>\n\n#include \"config.h\"\n\n#include \"antenna.h\"\n#include \"delay.h\"\n#include \"options.h\"\n#include \"pipeline.h\"\n\n#if AUDIO\n#include \"RtAudio.h\"\n#endif\n\n#include <Eigen/Dense>\n#include <WaraPSClient.h>\n#include <cmath>\n#include <cstdlib>\n#include <iostream>\n\n#include <opencv2/core/core.hpp>\n#include <opencv2/highgui/highgui.hpp>\n#include <opencv2/opencv.hpp>\n\n#include <signal.h>\n\n#include <atomic>\n#include <cmath>\n#include <cstdlib>\n#include <iostream>\n#include <thread>\n\n#define VALID_SENSOR(i) (64 <= i) && (i < 128)\n\n/**\nMain application for running beamformer program\n\nYou may try to use:\n\nsudo chrt -f 98 ./beamformer\n\nfor better performace by altering the real-time scheduling attributes of the\nprogram.\n\n */\n\nstd::atomic_int canPlot = 0;\n\nPipeline *pipeline;\n\n// Intermediate heatmap used for beamforming (8-bit)\ncv::Mat magnitudeHeatmap(Y_RES, X_RES, CV_8UC1);\n\n/**\n * @brief Calculate delays for different angles beforehand\n *\n * @param fractional_delays delays to use\n * @param antenna antenna structure\n * @param fov field of view\n * @param resolution_x width resolution\n * @param resolution_y height resolution\n */\nvoid compute_scanning_window(int *offset_delays, float *fractional_delays,\n                             const Antenna &antenna, float fov,\n                             int resolution_x, int resolution_y) {\n\n  float half_x = (float)(resolution_x) / 2 - 0.5;\n  float half_y = (float)(resolution_y) / 2 - 0.5;\n  int k = 0;\n  for (int x = 0; x < resolution_x; x++) {\n    for (int y = 0; y < resolution_y; y++) {\n\n      // Imagine dome in spherical coordinates on the XY-plane with Z being\n      // height\n      float xo = (float)(x - half_x) / (resolution_x);\n      float yo = (float)(y - half_y) / (resolution_y);\n      float level = sqrt(xo * xo + yo * yo) / 1;\n      level = sqrt(1 - level * level);\n      Position point(xo, yo, level);\n      // cout << point << endl;\n\n      VectorXf tmp_delays = steering_vector(antenna, point);\n      int i = 0;\n      for (float del : tmp_delays) {\n        double _offset;\n        float fraction;\n\n        fraction = (float)modf((double)del, &_offset);\n\n        int offset = N_SAMPLES - (int)_offset;\n        // cout << del << endl;\n        fractional_delays[k * N_SENSORS + i] = fraction;\n        offset_delays[k * N_SENSORS + i] = offset;\n        i++;\n      }\n\n      k++;\n    }\n  }\n}\n\n/**\n * @brief Convert multiple input streams into single level by delay\n *\n * @param t_id [TODO:parameter]\n * @param task pool partition\n * @param fractional_delays delays to use\n * @param rb ring buffer to use\n * @return power level\n */\nfloat miso(int t_id, int task, int *offset_delays, float *fractional_delays,\n           Streams *streams) {\n  float out[N_SAMPLES] = {0.0};\n  int n = 0;\n  for (int s = 0; s < N_SENSORS; s++) {\n\n    // if (!((s == 64) || (s == 64 + 8) || (s == 127 - 16) || (s == 127))) {\n    //   continue;\n    // }\n\n    if (VALID_SENSOR(s)) {\n      float fraction = fractional_delays[s - 64];\n      int offset = offset_delays[s - 64];\n\n      float *signal = (float *)((char *)streams->buffers[s] +\n                                streams->position + offset * sizeof(float));\n\n      for (int i = 0; i < N_SAMPLES; i++) {\n        out[i] += signal[i + 1] + fraction * (signal[i] - signal[i + 1]);\n      }\n\n      n++;\n    }\n  }\n\n  float power = 0.f;\n  float norm = 1 / (float)n;\n  for (int p = 0; p < N_SAMPLES; p++) {\n\n    power += powf(out[p] * norm, 2);\n  }\n\n  return power / (float)N_SAMPLES;\n}\n\n// If Audio playback when streaming\n#if AUDIO\n\nRtAudio audio;\nint play = 1;\nstd::thread *producer;\nstd::vector<float> audioBuffer(N_SAMPLES * 2, 0.0);\n\n/**\n * @brief Producer for audio on pipeline\n *\n * @param pipeline Pipeline\n */\nvoid audio_producer(Pipeline &pipeline) {\n\n  ring_buffer &rb = pipeline.getRingBuffer();\n\n  float out[N_SAMPLES] = {0.0};\n\n  while (pipeline.isRunning()) {\n\n    for (int i = 0; i < N_SAMPLES; i++) {\n      out[i] /= 64.f;\n\n      out[i] *= 100.f;\n      audioBuffer[i * 2] = out[i];\n      audioBuffer[i * 2 + 1] = out[i];\n      out[i] = 0.0;\n    }\n    play = 0;\n\n    pipeline.barrier();\n\n    // for (int s = 0; s < N_SENSORS; s++) {\n    //\n    //   if (VALID_SENSOR(s)) {\n    //     // cout << s << \" \";\n    //     naive_delay(&rb, &out[0], 0.0, s);\n    //   }\n    // }\n\n    naive_delay(&rb, &out[0], 0.0, 140);\n\n    // for (int i = 0; i < N_SAMPLES; i++) {\n    //   audioBuffer[i * 2] = rb.data[140][rb.index + i];\n    //   audioBuffer[i * 2 + 1] = rb.data[140][rb.index + i];\n    // }\n\n    // cout << \"run\" << endl;\n\n    // memcpy(&yrb.data[140][rb.index], &audioBuffer[0],\n    //        N_SAMPLES * sizeof(float));\n  }\n}\n\n/**\n * @brief Callback for audio stream\n *\n * @param outputBuffer Speaker buffer\n * @param inputBuffer empty (Required by RtAudio API)\n * @param nBufferFrames number of frames to fill\n * @param streamTime duration\n * @param status status\n * @param userData the incoming data\n * @return OK\n */\nint audioCallback(void *outputBuffer, void *inputBuffer,\n                  unsigned int nBufferFrames, double streamTime,\n                  RtAudioStreamStatus status, void *userData) {\n  float *buffer = (float *)outputBuffer;\n\n  // Copy samples from the sineBuffer to the output buffer for playback\n  for (unsigned int i = 0; i < N_SAMPLES * 2; ++i) {\n    if (!play) {\n      *buffer++ = audioBuffer[i];\n    } else {\n      cout << \"Underflow\" << endl;\n      *buffer++ = 0.0;\n    }\n  }\n\n  play = 1;\n\n  return 0;\n}\n\n/**\n * @brief Initiate Audio player for Pipeline\n *\n * @param pipeline the pipeline to follow\n * @return status\n */\nint init_audio_playback(Pipeline &pipeline) {\n  if (audio.getDeviceCount() < 1) {\n    std::cout << \"No audio devices found!\" << std::endl;\n    return EXIT_FAILURE;\n  }\n\n  RtAudio::StreamParameters parameters;\n  parameters.deviceId = audio.getDefaultOutputDevice();\n  parameters.nChannels = 2; // Stereo output\n\n  try {\n    unsigned int bufferFrames = N_SAMPLES;\n    audio.openStream(&parameters, nullptr, RTAUDIO_FLOAT32, 44100.f,\n                     &bufferFrames, &audioCallback);\n    audio.startStream();\n\n    producer = new std::thread(audio_producer, ref(pipeline));\n\n  } catch (RtAudioErrorType &e) {\n    // std::cout << \"Error: \" << e.getMessage() << std::endl;\n    return 1;\n  }\n\n  return 0;\n}\n\nvoid stop_audio_playback() {\n  // Start the separate thread for sine wave generation\n\n  // Keep the program running\n\n  // Stop the sine wave generation thread\n  producer->join();\n\n  // Stop and close the RtAudio stream\n  audio.stopStream();\n  audio.closeStream();\n}\n\n#endif\n\n/**\n * Beamforming as fast as possible on top of pipeline\n */\nvoid naive_seeker(Pipeline *pipeline) {\n\n  Antenna antenna = create_antenna(Position(0, 0, 0), COLUMNS, ROWS, DISTANCE);\n\n  float fractional_delays[X_RES * Y_RES * N_SENSORS];\n  int offset_delays[X_RES * Y_RES * N_SENSORS];\n\n  compute_scanning_window(&offset_delays[0], &fractional_delays[0], antenna,\n                          FOV, X_RES, Y_RES);\n\n  int max = X_RES * Y_RES;\n\n  float image[X_RES * Y_RES];\n\n  int pixel_index = 0;\n\n  int newData;\n  float power;\n  float threshold = 3e-8;\n\n  float norm = 1 / 1e-05;\n\n  float maxVal = 1.0;\n\n  Streams *streams = pipeline->getStreams();\n\n  while (pipeline->isRunning()) {\n\n    // Wait for incoming data\n    pipeline->barrier();\n\n    // This loop may run until new data has been produced, meaning its up to\n    // the machine to run as fast as possible\n    newData = pipeline->mostRecent();\n    float maxVal = 0.0;\n\n    int i = 0;\n    float mean = 0.0;\n\n    int xi, yi = 0;\n    float alpha = 1.0 / (float)(X_RES * Y_RES);\n    alpha = 0.02;\n\n    float heatmap_data[X_RES * Y_RES];\n\n    float avgPower = 0.0;\n\n    // Repeat until new data or abort if new data arrives\n    while ((pipeline->mostRecent() == newData) && (i < max)) {\n\n      int task = pixel_index * N_SENSORS;\n\n      xi = pixel_index % X_RES;\n      yi = pixel_index / X_RES;\n\n      // Get power level from direction\n      float val = miso(0, pixel_index, &offset_delays[task],\n                       &fractional_delays[task], streams);\n\n      if (val > maxVal) {\n        maxVal = val;\n      }\n\n      // power = val * 1e5;\n\n      // power = val * norm * 0.9f + 1.0;\n      power = val + 1.0f;\n      power = powf(power, 15);\n      // power *= 1e9f;\n\n      power = log(power) * 0.1f;\n\n      power = power * norm * 0.9f;\n\n      if (power < 0.2) {\n        power = 0.0f;\n      } else if (power > 1.0) {\n        norm *= 0.95;\n        // cout << \"Bigger value\" << endl;\n        power = 1.0f;\n      } else if (power < 0.0) {\n        power = 0.0f;\n        // cout << \"Negative value\" << endl;\n      }\n\n      // Paint pixel\n      magnitudeHeatmap.at<uchar>(yi, xi) = (uchar)(power * 255);\n\n      pixel_index++;\n      pixel_index %= X_RES * Y_RES;\n\n      i++;\n    }\n\n    canPlot = 1;\n\n    norm = (1 - alpha) * norm + alpha * (1 / (maxVal));\n\n    // norm = (1/maxVal) * 1.1f;\n\n    // cout << maxVal << endl;\n  }\n}\n\nvoid sig_handler(int sig) {\n  // Set the stop_processing flag to terminate worker threads gracefully\n  pipeline->disconnect();\n}\n\nint main() {\n  WaraPSClient client = WaraPSClient(\"test\", \"mqtt://localhost:25565\");\n  BeamformingOptions options;\n\n  client.set_command_callback(\"focus_bf\", [&](const nlohmann::json &payload) {\n    float theta = payload[\"theta\"];\n    float phi = payload[\"phi\"];\n    float duration =\n        payload.contains(\"duration\") ? (float)payload[\"duration\"] : 5.0f;\n\n    cout << \"Theta: \" << theta << \"\\nPhi: \" << phi << endl;\n    client.publish_message(\"exec/response\", string(\"Focusing beamformer for \" +\n                                                   to_string(duration)));\n  });\n\n  thread client_thread = client.start();\n\n  // Setup sigint i.e Ctrl-C\n  signal(SIGINT, sig_handler);\n\n  std::cout << \"Starting pipeline...\" << std::endl;\n  pipeline = new Pipeline();\n\n  std::cout << \"Waiting for UDP stream...\" << std::endl;\n  // Connect to UDP stream\n  pipeline->connect();\n\n  std::cout << \"Dispatching workers...\" << std::endl;\n  // Start beamforming thread\n  thread worker(naive_seeker, pipeline);\n\n  // Initiate background image\n  magnitudeHeatmap.setTo(cv::Scalar(0));\n\n#if AUDIO\n  init_audio_playback(pipeline);\n#endif\n\n#if CAMERA\n  cv::VideoCapture cap(CAMERA_PATH); // Open the default camera (change the\n                                     // index if you have multiple cameras)\n\n  if (!cap.isOpened()) {\n    std::cerr << \"Error: Unable to open the camera.\" << std::endl;\n    return -1;\n  }\n\n  while (pipeline->isRunning()) {\n    cv::Mat frame;\n    cap >> frame; // Capture a frame from the camera\n\n    if (frame.empty()) {\n      std::cerr << \"Error: Captured frame is empty.\" << std::endl;\n      break;\n    }\n\n    Mat overlayImage;\n    applyColorMap(magnitudeHeatmap, overlayImage, COLORMAP_JET);\n\n    // Resize the overlay image to match the dimensions of the webcam frame\n    cv::resize(overlayImage, overlayImage, frame.size());\n\n    // Overlay the image onto the webcam frame at a specified location (adjust\n    // as needed)\n    cv::Rect roi(0, 0, overlayImage.cols, overlayImage.rows);\n    cv::Mat imageROI = frame(roi);\n    cv::addWeighted(imageROI, 1.0, overlayImage, 0.5, 0, imageROI);\n\n    // Display the resulting frame with the overlay\n    cv::imshow(APPLICATION_NAME, frame);\n\n    if (waitKey(1) == 'q') {\n      // ok = false;\n      std::cout << \"Stopping\" << endl;\n\n      break;\n    }\n  }\n\n  // Release the camera and close all OpenCV windows\n  cap.release();\n#else\n\n  // Create a window to display the beamforming data\n  cv::namedWindow(APPLICATION_NAME, cv::WINDOW_NORMAL);\n  cv::resizeWindow(APPLICATION_NAME, APPLICATION_WIDTH, APPLICATION_HEIGHT);\n  int res = 16;\n\n  // Decay image onto previous frame\n  cv::Mat previous(Y_RES, X_RES, CV_8UC1);\n  previous.setTo(cv::Scalar(0)); // Set to zero\n  cv::applyColorMap(previous, previous, cv::COLORMAP_JET);\n\n#if RESIZE_HEATMAP\n  cv::resize(previous, previous, cv::Size(), res, res, cv::INTER_LINEAR);\n#endif\n\n  std::cout << \"Running...\" << std::endl;\n  while (pipeline->isRunning()) {\n    if (canPlot) {\n      canPlot = 0;\n      cv::Mat coloredMatrix;\n      // Blur the image with a Gaussian kernel\n      cv::GaussianBlur(magnitudeHeatmap, magnitudeHeatmap,\n                       cv::Size(BLUR_KERNEL_SIZE, BLUR_KERNEL_SIZE), 0);\n\n      // Apply color map\n      cv::applyColorMap(magnitudeHeatmap, coloredMatrix, cv::COLORMAP_JET);\n\n#if RESIZE_HEATMAP\n      // Resize to smoothen\n      cv::resize(coloredMatrix, coloredMatrix, cv::Size(), res, res,\n                 cv::INTER_LINEAR);\n#endif\n      // Combine previous images for more smooth image\n      cv::addWeighted(coloredMatrix, 0.1, previous, 0.9, 0, coloredMatrix);\n\n      // Update previous image\n      previous = coloredMatrix;\n\n      // Output image to screen\n      cv::imshow(APPLICATION_NAME, coloredMatrix);\n    }\n\n    // Check for key press; if 'q' is pressed, break the loop\n    if (!client.running() || cv::waitKey(1) == 'q') {\n      std::cout << \"Stopping application...\" << std::endl;\n      break;\n    }\n  }\n\n#endif\n\n#if DEBUG_BEAMFORMER\n  // Save all data\n  pipeline->save_pipeline(\"pipeline.bin\");\n#endif\n\n  std::cout << \"Disconnecting pipeline...\" << std::endl;\n  // Stop UDP stream\n  pipeline->disconnect();\n\n#if AUDIO\n  stop_audio_playback();\n#endif\n\n  std::cout << \"Closing application...\" << std::endl;\n  // Close application windows\n  cv::destroyAllWindows();\n\n  std::cout << \"Waiting for workers...\" << std::endl;\n  // Join the workers\n  worker.join();\n  client_thread.join();\n\n  std::cout << \"Exiting...\" << std::endl;\n\n  // Cleanup\n  delete pipeline;\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/beamformer.cpp b/src/beamformer.cpp
--- a/src/beamformer.cpp	
+++ b/src/beamformer.cpp	
@@ -12,7 +12,7 @@
 #endif
 
 #include <Eigen/Dense>
-#include <WaraPSClient.h>
+#include <waraps_client.h>
 #include <cmath>
 #include <cstdlib>
 #include <iostream>
Index: CMakeLists.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>cmake_minimum_required(VERSION 3.10.1)\nproject(beamformer VERSION 1.0.1)\n\n\n# Optimizations\nif (NOT CMAKE_BUILD_TYPE)\n    set(CMAKE_BUILD_TYPE Release)\nendif ()\n\nIF (NOT PYTHON)\n    find_program(PYTHON \"python3\")\nENDIF ()\n\n\nset(CMAKE_BUILD_DIR \"${CMAKE_CURRENT_SOURCE_DIR}/build\")\n\n\n# ---- Configuration ----\nset(CONFIG_FILE ${CMAKE_CURRENT_SOURCE_DIR}/config.yaml)\nset(CONFIG_MAKER \"${CMAKE_CURRENT_SOURCE_DIR}/scripts/config_maker.py\")\n\n\nadd_custom_command(\n        DEPENDS ${CONFIG_FILE}\n\n        # Generate Cython module/src/config.pxd\n        COMMAND ${PYTHON} ${CONFIG_MAKER} ${CONFIG_FILE} ${CMAKE_CURRENT_SOURCE_DIR}/module/src --cython\n        OUTPUT ${CMAKE_CURRENT_SOURCE_DIR}/module/src/config.pxd\n\n        # Generate Python build/config.py\n        COMMAND ${PYTHON} ${CONFIG_MAKER} ${CONFIG_FILE} ${CMAKE_CURRENT_BINARY_DIR} --python\n        OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/config.py\n        # cp ${CMAKE_CURRENT_BINARY_DIR}/config.py ${CMAKE_CURRENT_SOURCE_DIR}/module/config.py\n        #\n\n        OUTPUT ${CMAKE_CURRENT_SOURCE_DIR}/module/config.py\n        COMMAND ${CMAKE_COMMAND} -E copy\n        ${CMAKE_CURRENT_BINARY_DIR}/config.py\n        ${CMAKE_CURRENT_SOURCE_DIR}/module/config.py\n\n        #DEPENDS ${CMAKE_CURRENT_SOURCE_DIR}/${MY_RESOURCE_FILE}\n        # OUTPUT ${CMAKE_CURRENT_SOURCE_DIR}/module/config.py\n        COMMAND ${CMAKE_COMMAND} -E touch ${CMAKE_CURRENT_BINARY_DIR}/__init__.py\n\n        # Generate C/C++ config.h\n        COMMAND ${PYTHON} ${CONFIG_MAKER} ${CONFIG_FILE} ${CMAKE_CURRENT_SOURCE_DIR}/src --c\n        OUTPUT ${CMAKE_CURRENT_SOURCE_DIR}/src/config.h\n)\n\nset(CONFIGURATIONS\n        ${CONFIG_FILE}\n        ${CMAKE_CURRENT_BINARY_DIR}/config.py\n        ${CMAKE_CURRENT_SOURCE_DIR}/src/config.h\n        ${CMAKE_CURRENT_SOURCE_DIR}/module/src/config.pxd\n)\n\nadd_custom_target(config DEPENDS ${CONFIGURATIONS})\n\n\n# ---- Cython module ----\nset(CMAKE_MODULE_DIR \"${CMAKE_CURRENT_SOURCE_DIR}/module\")\nset(SETUP_PY_IN \"${CMAKE_MODULE_DIR}/setup.py.in\")\nset(SETUP_PY \"${CMAKE_MODULE_DIR}/setup.py\")\nset(PY_OUTPUT \"${CMAKE_CURRENT_BINARY_DIR}/build/pytimestamp\")\n\n\nconfigure_file(\n        ${SETUP_PY_IN}\n        ${SETUP_PY}\n)\n\n# Define the Python virtual environment directory\nset(PYTHON_VENV_DIR \"${CMAKE_MODULE_DIR}/venv\")\n\n# Define the command to create the virtual environment\nset(CREATE_VENV_COMMAND \"${PYTHON}\" -m venv \"${PYTHON_VENV_DIR}\")\n\n# Define the commands to install dependencies inside the virtual environment\nset(INSTALL_DEPENDENCIES_COMMAND\n        \"${PYTHON_VENV_DIR}/bin/pip\" install -r ${CMAKE_MODULE_DIR}/requirements.txt\n        COMMENT \"Done installing \"\n)\n\nset(PYTHON \"${PYTHON_VENV_DIR}/bin/python\")\n\n# Define a custom target to create the virtual environment and install dependencies\nadd_custom_command(\n        OUTPUT ${PYTHON_VENV_DIR}\n        COMMAND ${CREATE_VENV_COMMAND}\n        COMMAND ${INSTALL_DEPENDENCIES_COMMAND}\n        COMMENT \"Creating Python virtual environment and installing dependencies\"\n        WORKING_DIRECTORY \"${CMAKE_SOURCE_DIR}\"\n)\n\nset(MODULE_SOURCES\n        ${CMAKE_MODULE_DIR}/src/config.pxd\n        ${CMAKE_MODULE_DIR}/src/antenna.pyx\n        ${CMAKE_MODULE_DIR}/src/antenna.pxd\n        ${CMAKE_MODULE_DIR}/src/eigen.pxd\n        ${CMAKE_MODULE_DIR}/src/pipeline.pyx\n        ${CMAKE_MODULE_DIR}/src/pipeline.pxd\n)\n\n\nadd_custom_command(DEPENDS ${PYTHON_VENV_DIR} ${MODULE_SOURCES}\n        OUTPUT \"${PY_OUTPUT}\"\n\n        # Build modules\n        COMMENT \"Starting build\"\n        COMMAND ${PYTHON} ${SETUP_PY} build_ext\n        # COMMAND ${PYTHON_VENV_DIR}/bin/python ${SETUP_PY} build_ext\n        #--build-lib=lib --build-temp=build\n\n        # Generate timestamp\n        COMMAND ${CMAKE_COMMAND} -E touch ${PY_OUTPUT}\n)\n\n\nadd_custom_target(module DEPENDS ${PY_OUTPUT})\n\n\n# ---- Program ----\n# Find packages\n\n\n# Matrix operations\nfind_package(Eigen3 REQUIRED)\n\n# MQTT Communication\nfind_package(nlohmann_json REQUIRED)\nfind_package(WaraPSClient REQUIRED)\n\n# Generating UUID:s\nfind_package(Boost REQUIRED)\n\n\n# Find OpenCV package\nfind_package(OpenCV REQUIRED)\n\nfind_package(PkgConfig REQUIRED)\npkg_check_modules(RtAudio REQUIRED IMPORTED_TARGET rtaudio)\n\n# Include directories for OpenCV\ninclude_directories(${OpenCV_INCLUDE_DIRS})\n\n# # Configuration maker\n# add_custom_target(config #ALL DEPENDS\n#   \n#   # Generate C/C++ config.h\n#   COMMAND ${PYTHON} ${CMAKE_CURRENT_SOURCE_DIR}/scripts/config_maker.py ${CMAKE_CURRENT_SOURCE_DIR}/config.yaml ${CMAKE_CURRENT_SOURCE_DIR}/src --c\n#\n#   # Python \n#   COMMAND ${PYTHON} ${CMAKE_CURRENT_SOURCE_DIR}/scripts/config_maker.py ${CMAKE_CURRENT_SOURCE_DIR}/config.yaml ${CMAKE_CURRENT_BINARY_DIR} --python\n#\n# )\n#  add_executable(audio \n# ${CMAKE_CURRENT_SOURCE_DIR}/src/audio.cpp\n# )\n#\n#\n# target_link_libraries(audio PkgConfig::RtAudio)\n\nset(SOURCES\n        ${CMAKE_CURRENT_SOURCE_DIR}/src/receiver.cpp\n        ${CMAKE_CURRENT_SOURCE_DIR}/src/antenna.cpp\n        ${CMAKE_CURRENT_SOURCE_DIR}/src/pipeline.cpp\n        ${CMAKE_CURRENT_SOURCE_DIR}/src/ring_buffer.cpp\n        ${CMAKE_CURRENT_SOURCE_DIR}/src/beamformer.cpp\n        ${CMAKE_CURRENT_SOURCE_DIR}/src/options.cpp\n)\n\n\n# Main program\nadd_executable(beamformer\n        ${CMAKE_CURRENT_SOURCE_DIR}/src/config.h\n\n        ${SOURCES}\n)\n\n\n# Linking\ntarget_link_libraries(beamformer\n        Eigen3::Eigen\n        PkgConfig::RtAudio\n        WaraPSClient::WaraPSClient\n        nlohmann_json::nlohmann_json\n        ${OpenCV_LIBS}\n)\n\ntarget_include_directories(beamformer PUBLIC ${Boost_INCLUDE_DIRS})\n\n\nadd_dependencies(beamformer config)\n\nadd_custom_target(test.udp\n        COMMAND echo \"Generating fake stream to localhost\"\n        COMMAND udpreplay -i lo ${CMAKE_CURRENT_SOURCE_DIR}/udp/converted/test.pcap\n)\n\n# # Testbench\n# add_custom_target(test\n#   COMMAND ${PYTHON} -m unittest discover -s ${CMAKE_CURRENT_SOURCE_DIR} -vv #--failfast\n# )\n\nadd_custom_target(test\n        # COMMAND ${PYTHON} -m unittest discover -s ..\n        # COMMAND bash ${CMAKE_CURRENT_SOURCE_DIR}/tests/test.sh\n        COMMAND ${PYTHON} -m unittest discover -s ${CMAKE_CURRENT_SOURCE_DIR} -vv #--failfast\n\n)\n\n# Documentation\nadd_custom_target(doc\n        COMMAND doxygen ${CMAKE_CURRENT_SOURCE_DIR}/Doxyfile\n)\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/CMakeLists.txt b/CMakeLists.txt
--- a/CMakeLists.txt	
+++ b/CMakeLists.txt	
@@ -122,13 +122,24 @@
 # ---- Program ----
 # Find packages
 
+include(FetchContent)
+
+find_package(WaraPSClient REQUIRED)
+
+FetchContent_Declare(
+        WaraPSClient
+        GIT_REPOSITORY https://github.com/acoustic-warfare/WARA-PS-MQTT-Agent.git
+        GIT_TAG        main
+)
+
+FetchContent_MakeAvailable(WaraPSClient)
 
 # Matrix operations
 find_package(Eigen3 REQUIRED)
 
 # MQTT Communication
 find_package(nlohmann_json REQUIRED)
-find_package(WaraPSClient REQUIRED)
+
 
 # Generating UUID:s
 find_package(Boost REQUIRED)
@@ -173,7 +184,6 @@
 # Main program
 add_executable(beamformer
         ${CMAKE_CURRENT_SOURCE_DIR}/src/config.h
-
         ${SOURCES}
 )
 
